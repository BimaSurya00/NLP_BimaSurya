# -*- coding: utf-8 -*-
"""bimasurya_nlp

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1c87CDQYKhkal1VLLqERXDtb3O7Y0PUqi

Bima Surya Nurwahid

Dataset : https://www.kaggle.com/datasets/ramadhaniduma/tripadvisor-hotel-reviews
"""

!kaggle datasets download -d ramadhaniduma/tripadvisor-hotel-reviews

import zipfile

zip_ref = zipfile.ZipFile("/content/tripadvisor-hotel-reviews.zip", 'r')
zip_ref.extractall('/content')
zip_ref.close()

import csv
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import regex as re
import nltk as nltk
from nltk import corpus
from nltk.stem import PorterStemmer
from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.layers import LSTM,Dense,Embedding,Dropout
from tensorflow.keras.models import Sequential
from tensorflow.keras.optimizers import Adam

missing_values = ["n/a", "na", "--"]
df = pd.read_csv('/content/tripadvisor_hotel_reviews.csv', encoding='latin-1')
df.head()

df.isna().sum()

def tokenize(text):
    split=re.split("\W+",text) 
    return split
df['review_text_split']=df['Review'].apply(lambda x: tokenize(x.lower()))
df.head(100)

nltk.download('stopwords')
stopword = nltk.corpus.stopwords.words('english')
print(stopword[:20])

def remove_stopwords(text):
    text=[word for word in text if word not in stopword]
    return text
df['review_text_stopwords'] = df['review_text_split'].apply(lambda x: remove_stopwords(x))
df.head(1000)

stemmer = nltk.stem.SnowballStemmer(language='english')
def stem_list(row):
    my_list = row['review_text_stopwords']
    stemmed_list = [stemmer.stem(word) for word in my_list]
    return (stemmed_list)

df['stemmed_review'] = df.apply(stem_list, axis=1)

def rating_group(rate):
    group = rate['Rating']
    if rate['Rating'] > 3:
        grouped_rate = 'Good'
    elif rate['Rating'] == 3:
        grouped_rate = 'Neutral'
    elif rate['Rating'] < 3:
        grouped_rate = 'Bad'
    return (grouped_rate)

df['new_rating'] = df.apply(rating_group, axis=1)

rating_category = pd.get_dummies(df.new_rating)
df_new = pd.concat([df, rating_category], axis=1)
df_new = df_new.drop(columns='Rating')
df_new

review = df_new['stemmed_review'].values
label = df_new[['Bad','Good','Neutral']].values
label

print(review.shape, label.shape)

x_train,x_test,y_train,y_test = train_test_split(review, label, test_size = 0.2,shuffle=True)

tokenizer = Tokenizer(num_words=10000, oov_token='x')
tokenizer.fit_on_texts(x_train)
tokenizer.fit_on_texts(x_test)

sekuens_train = tokenizer.texts_to_sequences(x_train)
sekuens_test = tokenizer.texts_to_sequences(x_test)
 
padded_train = pad_sequences(sekuens_train)
padded_test = pad_sequences(sekuens_test)

print(padded_test.shape)

model = tf.keras.Sequential([
    tf.keras.layers.Embedding(input_dim=50000, output_dim=16),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.LSTM(128),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(3, activation='softmax')
     ])

model.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])
model.summary()

class nlpCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy')>0.8 and logs.get('val_accuracy')>0.8):
      self.model.stop_training = True
      print("\nAkurasi train telah mencapai nilai > 90%!")

callbacks = nlpCallback()

epoch=100
history = model.fit(padded_train, 
                    y_train,
                    batch_size=32, 
                    epochs=epoch,
                    validation_data=(padded_test, y_test), 
                    verbose=2,
                    callbacks=[callbacks]
                    )